{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 1: Import Libraries***"
      ],
      "metadata": {
        "id": "QGlTFoQ-5Kop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0c-LbN04vfJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import ResNet50, MobileNetV3Small\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from glob import glob\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 2: Load and Organize Data***"
      ],
      "metadata": {
        "id": "9Di2-w1p5RiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths\n",
        "dataset_path = \"path/to/dataset\"  # Update with your dataset path\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "test_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"cricket\", \"tennis\", \"badminton\", \"swimming\"]\n",
        "\n",
        "# Print dataset structure\n",
        "for label in class_labels:\n",
        "    print(f\"{label}: {len(os.listdir(os.path.join(train_path, label)))} images\")\n"
      ],
      "metadata": {
        "id": "rh4avqzs5IY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 3: Data Preprocessing***"
      ],
      "metadata": {
        "id": "qLAOwGhL5bPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image parameters\n",
        "IMG_SIZE = (224, 224)  # Resize images\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "# Train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Test data generator (without augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "_C6c9fMQ5cvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 4: Define Deep Neural Network (DNN) Model***"
      ],
      "metadata": {
        "id": "yAzXH2255lH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')  # 4 classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "dnn_model = build_dnn()\n",
        "dnn_model.summary()\n"
      ],
      "metadata": {
        "id": "biV4GCF45ZDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 5: Train DNN Model***"
      ],
      "metadata": {
        "id": "epf6d5YM5pS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dnn = dnn_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "PQNo85D35otE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 6: Load Pretrained ResNet50 Model***"
      ],
      "metadata": {
        "id": "FU6Uymnh5sCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze layers\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "resnet50_model = build_resnet50()\n",
        "resnet50_model.summary()\n"
      ],
      "metadata": {
        "id": "nrM2fD0t5vfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 7: Train ResNet50 Model***\n"
      ],
      "metadata": {
        "id": "fz5_5uh55xp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet50 = resnet50_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "hLtJGTKd5z8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 8: Load Pretrained MobileNetV3 Model***"
      ],
      "metadata": {
        "id": "Dv729H3_55yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mobilenetv3():\n",
        "    base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze layers\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "mobilenetv3_model = build_mobilenetv3()\n",
        "mobilenetv3_model.summary()\n"
      ],
      "metadata": {
        "id": "P-K0frlT55Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 7: Train MobileNetV3 Model***\n"
      ],
      "metadata": {
        "id": "XFpjUzOR6ByZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_mobilenetv3 = mobilenetv3_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "dxN3OfmZ5-ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 10: Evaluate Models***"
      ],
      "metadata": {
        "id": "ELevDyb26HfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, model_name):\n",
        "    y_pred = np.argmax(model.predict(val_generator), axis=1)\n",
        "    y_true = val_generator.classes\n",
        "    print(f\"Classification Report for {model_name}:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate each model\n",
        "evaluate_model(dnn_model, \"DNN\")\n",
        "evaluate_model(resnet50_model, \"ResNet50\")\n",
        "evaluate_model(mobilenetv3_model, \"MobileNetV3\")\n"
      ],
      "metadata": {
        "id": "3bD36Igf6F0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Step 11: Plot Accuracy & Loss Graphs***"
      ],
      "metadata": {
        "id": "5AVOWQ4I6MmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, model_name):\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f\"{model_name} Accuracy over Epochs\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f\"{model_name} Loss over Epochs\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot for each model\n",
        "plot_history(history_dnn, \"DNN\")\n",
        "plot_history(history_resnet50, \"ResNet50\")\n",
        "plot_history(history_mobilenetv3, \"MobileNetV3\")\n"
      ],
      "metadata": {
        "id": "RwgogGVn6KxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}